{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36a262f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(dotenv_path=\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cd395a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"VLAM_API_KEY\")\n",
    "base_url = os.environ.get(\"VLAM_BASE_URL\", \"https://api.demo.vlam.ai/v2.1/projects/poc/openai-compatible/v1\")\n",
    "# model_id = os.environ.get(\"VLAM_MODEL_ID\", \"ubiops-deployment/bzk-bsw-chat//chat-model\")\n",
    "model_id = os.environ.get(\"VLAM_MODEL_ID\", \"ubiops-deployment/bzk-bsw-mistralmedium-flexibel//chat-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1cf9b3",
   "metadata": {},
   "source": [
    "## openai (OpenAI) test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868686f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key, base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd25ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens: int = 2000\n",
    "temperature: float = 0.7\n",
    "system: str | None = None\n",
    "# request: Request | None = None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97647166",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"You are a helpful assistant.\"\n",
    "\n",
    "def chat_completion(messages):\n",
    "    all_messages = messages.copy()\n",
    "    if system:\n",
    "        all_messages.insert(0, {\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        # system=system,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca7ef4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-b833b478ef5f4f48bdac7b0b537e89e4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm just a language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to assist you with any questions or topics you'd like to discuss. How about you? How's your day going so far?\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content=None), stop_reason=None)], created=1761125133, model='llama-3.3-70b-instruct-awq', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=55, prompt_tokens=41, total_tokens=96, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion([{\"role\": \"user\", \"content\": \"Hello, how are you?\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c029a",
   "metadata": {},
   "source": [
    "## Langchain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ee9277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc54683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b25711",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=model_id,\n",
    "    openai_api_key=api_key,\n",
    "    base_url=base_url,\n",
    "    temperature=0.7,\n",
    "    max_tokens=2000,\n",
    "    model=model_id,\n",
    "    stream_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5103d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bf4808c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How about you? How's your day going so far?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 41, 'total_tokens': 94, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama-3.3-70b-instruct-awq', 'system_fingerprint': None, 'id': 'chatcmpl-7af504aa95914cfdbb33fcd903372232', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a82dbcdc-82cf-48a3-afec-8601ef118c0d-0', usage_metadata={'input_tokens': 41, 'output_tokens': 53, 'total_tokens': 94, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "989e7e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to assist you with any questions or tasks you may have. How about you? How's your day going so far?\n",
      "{\n",
      "  \"refusal\": null\n",
      "}\n",
      "{\n",
      "  \"token_usage\": {\n",
      "    \"completion_tokens\": 53,\n",
      "    \"prompt_tokens\": 41,\n",
      "    \"total_tokens\": 94,\n",
      "    \"completion_tokens_details\": null,\n",
      "    \"prompt_tokens_details\": null\n",
      "  },\n",
      "  \"model_provider\": \"openai\",\n",
      "  \"model_name\": \"llama-3.3-70b-instruct-awq\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"id\": \"chatcmpl-7af504aa95914cfdbb33fcd903372232\",\n",
      "  \"finish_reason\": \"stop\",\n",
      "  \"logprobs\": null\n",
      "}\n",
      "\n",
      "##############\n",
      "\n",
      "Model name: llama-3.3-70b-instruct-awq\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(response.content)\n",
    "print(json.dumps(response.additional_kwargs, indent=2))\n",
    "print(json.dumps(response.response_metadata, indent=2))\n",
    "\n",
    "print(\"\\n##############\\n\")\n",
    "print(\"Model name:\", response.response_metadata[\"model_name\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
